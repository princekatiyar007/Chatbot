
<script>
  // Function to add a fullscreen button to an image
  function addFullscreenButton(imageId) {
    const image = document.getElementById(imageId);
    const container = image.parentElement;

    // Create button
    const button = document.createElement("button");
    button.innerHTML = "üîç"; // Or replace with SVG icon
    button.title = "View Fullscreen";

    // Style the button with Tailwind classes
    button.className =
      "absolute top-2 right-2 bg-black bg-opacity-50 p-2 rounded-full text-white hover:bg-opacity-75";

    // Add click event
    button.onclick = () => {
      if (image.requestFullscreen) {
        image.requestFullscreen();
      } else if (image.webkitRequestFullscreen) {
        image.webkitRequestFullscreen(); // Safari
      } else if (image.msRequestFullscreen) {
        image.msRequestFullscreen(); // IE
      }
    };

    // Ensure container has relative positioning
    if (!container.classList.contains("relative")) {
      container.classList.add("relative");
    }

    // Append the button
    container.appendChild(button);
  }

  // Call the function after DOM is loaded
  addFullscreenButton("myImage");
</script>








import React, { useState } from "react";

function AudioGenerator() {
  const [topic, setTopic] = useState("");
  const [audioUrl, setAudioUrl] = useState(null);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState("");

  const handleSubmit = async (e) => {
    e.preventDefault();
    setLoading(true);
    setError("");
    setAudioUrl(null);

    try {
      // 1Ô∏è‚É£ First API: Get Script
      const res1 = await fetch("https://api1.example.com", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ topic }),
      });
      const data1 = await res1.json();
      const script = data1.result; // adjust to actual key

      // 2Ô∏è‚É£ Second API: Get Audio
      const res2 = await fetch("https://api2.example.com", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ script }),
      });

      if (!res2.ok) throw new Error("Audio generation failed");

      const audioBlob = await res2.blob();
      const audioObjectUrl = URL.createObjectURL(audioBlob);
      setAudioUrl(audioObjectUrl);
    } catch (err) {
      setError("Something went wrong: " + err.message);
      console.error(err);
    }

    setLoading(false);
  };

  return (
    <div className="min-h-screen bg-gradient-to-br from-gray-900 via-gray-800 to-gray-900 text-white flex items-center justify-center p-4">
      <div className="bg-gray-800 rounded-2xl shadow-2xl p-8 w-full max-w-2xl">
        <h1 className="text-3xl font-bold mb-6 text-center">üé§ Script to Audio Generator</h1>

        <form onSubmit={handleSubmit} className="space-y-4">
          <textarea
            className="w-full p-4 h-32 rounded-lg bg-gray-700 border border-gray-600 focus:outline-none focus:ring-2 focus:ring-blue-500 resize-none text-white placeholder-gray-400"
            placeholder="Enter your topic here..."
            value={topic}
            onChange={(e) => setTopic(e.target.value)}
          />

          <button
            type="submit"
            className="w-full bg-blue-600 hover:bg-blue-700 transition duration-200 text-white font-bold py-3 rounded-lg"
            disabled={loading}
          >
            {loading ? "Generating Audio..." : "Submit"}
          </button>
        </form>

        {error && (
          <div className="mt-4 text-red-400 text-center font-medium">{error}</div>
        )}

        {audioUrl && (
          <div className="mt-8">
            <h2 className="text-xl font-semibold mb-2 text-center">üîä Your Audio Output</h2>
            <audio
              className="w-full mt-2 rounded-lg"
              controls
              src={audioUrl}
            />
          </div>
        )}
      </div>
    </div>
  );
}

export default AudioGenerator;







module.exports = {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
};







/** @type {import('tailwindcss').Config} */
module.exports = {
  content: ["./src/**/*.{js,jsx,ts,tsx}"],
  theme: {
    extend: {},
  },
  plugins: [],
};







import React, { useState } from "react";

function AudioGenerator() {
  const [topic, setTopic] = useState("");
  const [audioUrl, setAudioUrl] = useState(null);
  const [loading, setLoading] = useState(false);

  const handleSubmit = async (e) => {
    e.preventDefault();
    setLoading(true);
    setAudioUrl(null);

    try {
      // üîπ Step 1: Send topic to API 1
      const res1 = await fetch("https://api1.example.com", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({ topic }),
      });

      const data1 = await res1.json();
      const script = data1.result; // Adjust based on API 1's response format

      // üîπ Step 2: Send script to API 2 and get audio stream
      const res2 = await fetch("https://api2.example.com", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({ script }),
      });

      if (!res2.ok) {
        throw new Error("Failed to get audio");
      }

      const audioBlob = await res2.blob(); // Convert audio stream to blob
      const audioObjectUrl = URL.createObjectURL(audioBlob); // Convert blob to playable URL
      setAudioUrl(audioObjectUrl); // Set URL for audio player

    } catch (error) {
      console.error("Error generating audio:", error);
    }

    setLoading(false);
  };

  return (
    <div className="p-8 max-w-xl mx-auto">
      <form onSubmit={handleSubmit}>
        <textarea
          value={topic}
          onChange={(e) => setTopic(e.target.value)}
          placeholder="Enter topic"
          className="w-full h-32 p-2 border border-gray-400 rounded mb-4"
        />
        <button
          type="submit"
          className="bg-black text-white px-4 py-2 rounded hover:bg-gray-800"
        >
          Generate Audio
        </button>
      </form>

      {loading && <p className="mt-4">Generating audio...</p>}

      {audioUrl && (
        <div className="mt-6">
          <audio controls src={audioUrl} className="w-full" />
        </div>
      )}
    </div>
  );
}

export default AudioGenerator;





import React from "react";
import "./index.css"; // optional, use for Tailwind/custom styles
import HomePage from "./HomePage";

function App() {
  return <HomePage />;
}

export default App;






import React, { useState } from "react";

function HomePage() {
  const [topic, setTopic] = useState("");
  const [response, setResponse] = useState("");

  const handleSubmit = async (e) => {
    e.preventDefault();

    try {
      const res = await fetch("https://your-api.com/endpoint", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({ topic: topic }),
      });

      const data = await res.json();
      setResponse(data.result); // Change this based on actual API response
    } catch (err) {
      console.error("Error:", err);
      setResponse("Something went wrong.");
    }
  };

  return (
    <div className="p-8 max-w-xl mx-auto">
      <form onSubmit={handleSubmit}>
        <textarea
          value={topic}
          onChange={(e) => setTopic(e.target.value)}
          placeholder="Enter topic here"
          className="w-full h-32 p-2 border border-gray-400 rounded mb-4"
        />
        <button
          type="submit"
          className="bg-black text-white px-4 py-2 rounded hover:bg-gray-800"
        >
          Submit
        </button>
      </form>

      {response && (
        <div className="mt-6 p-4 border border-gray-300 rounded bg-gray-50">
          <h3 className="font-bold">Response:</h3>
          <p>{response}</p>
        </div>
      )}
    </div>
  );
}

export default HomePage;















<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Input Page</title>
</head>
<body>
  <h2>Enter Query</h2>
  <input type="text" id="queryInput" placeholder="Type something..." />
  <button onclick="submitQuery()">Submit</button>

  <script src="js/index.js"></script>
</body>
</html>




<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Result Page</title>
</head>
<body>
  <h2>Processed Output</h2>
  <p id="displayQuery"></p>

  <script src="js/index.js"></script>
</body>
</html>




// Detect current page
const path = window.location.pathname;

// Page 1: index.html ‚Äì just redirect with raw input
if (path.endsWith("index.html")) {
  window.submitQuery = function () {
    const rawQuery = document.getElementById("queryInput").value.trim();
    if (rawQuery) {
      // Pass raw input to result page (not processed yet)
      const encoded = encodeURIComponent(rawQuery);
      window.location.href = `result.html?q=${encoded}`;
    }
  };
}

// Page 2: result.html ‚Äì receive raw input and process it
if (path.endsWith("result.html")) {
  const params = new URLSearchParams(window.location.search);
  const rawQuery = params.get("q");

  const displayEl = document.getElementById("displayQuery");
  if (rawQuery) {
    const processed = processQuery(rawQuery); // Process here
    displayEl.innerText = `Processed: ${processed}`;
  } else {
    displayEl.innerText = "No query provided.";
  }
}

// Example processing function
function processQuery(input) {
  // Transform raw input (e.g., lowercase ‚Üí uppercase)
  return input.toUpperCase();
}











import React, { useEffect, useRef, useState } from 'react';
import WaveSurfer from 'wavesurfer.js';

const Waveform = ({ audioUrl }) => {
  const waveformRef = useRef(null);
  const wavesurferRef = useRef(null);
  const [isPlaying, setIsPlaying] = useState(false);

  useEffect(() => {
    if (!waveformRef.current) return;

    // Cleanup old instance if re-rendered
    if (wavesurferRef.current) {
      wavesurferRef.current.destroy();
    }

    // Initialize WaveSurfer
    wavesurferRef.current = WaveSurfer.create({
      container: waveformRef.current,
      waveColor: '#94a3b8',
      progressColor: '#4ade80',
      cursorColor: '#22c55e',
      height: 100,
      responsive: true,
      barWidth: 2,
    });

    wavesurferRef.current.load(audioUrl);

    return () => {
      wavesurferRef.current.destroy();
    };
  }, [audioUrl]);

  const togglePlay = () => {
    if (wavesurferRef.current) {
      wavesurferRef.current.playPause();
      setIsPlaying(wavesurferRef.current.isPlaying());
    }
  };

  return (
    <div className="w-full max-w-2xl mx-auto mt-6">
      <div ref={waveformRef} className="rounded border border-green-500" />
      <button
        onClick={togglePlay}
        className="mt-3 px-4 py-2 bg-green-600 hover:bg-green-700 text-white font-semibold rounded"
      >
        {isPlaying ? 'Pause' : 'Play'}
      </button>
    </div>
  );
};

export default Waveform;











import React, { useEffect, useRef } from 'react';

const AudioVisualizer = ({ audioRef }) => {
  const canvasRef = useRef(null);
  const isInitialized = useRef(false); // ‚úÖ Track init

  useEffect(() => {
    if (!audioRef.current || isInitialized.current) return;

    const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    const analyser = audioCtx.createAnalyser();
    analyser.fftSize = 256;

    try {
      const source = audioCtx.createMediaElementSource(audioRef.current);
      source.connect(analyser);
      analyser.connect(audioCtx.destination);
    } catch (e) {
      console.error('Audio source already connected:', e);
      return;
    }

    isInitialized.current = true; // ‚úÖ Mark as initialized

    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    const canvas = canvasRef.current;
    const canvasCtx = canvas.getContext('2d');

    const draw = () => {
      requestAnimationFrame(draw);
      analyser.getByteFrequencyData(dataArray);

      canvasCtx.fillStyle = '#111827';
      canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

      const barWidth = (canvas.width / bufferLength) * 2.5;
      let x = 0;

      for (let i = 0; i < bufferLength; i++) {
        const barHeight = dataArray[i] / 2;
        canvasCtx.fillStyle = '#4ade80';
        canvasCtx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);
        x += barWidth + 1;
      }
    };

    draw();

    const resume = () => audioCtx.resume();
    audioRef.current.addEventListener('play', resume);

    return () => {
      if (audioRef.current) {
        audioRef.current.removeEventListener('play', resume);
      }
      audioCtx.close();
    };
  }, [audioRef]);

  return (
    <canvas
      ref={canvasRef}
      width={600}
      height={100}
      className="mt-4 border border-green-500 rounded"
    />
  );
};

export default AudioVisualizer;








import React, { useState, useEffect, useRef } from 'react';
import './index.css';
import InputSection from './components/InputSection';
import SpeakerDisplay from './components/SpeakerDisplay';
import AudioVisualizer from './components/AudioVisualizer';

function App() {
  const [text, setText] = useState('');
  const [speaker, setSpeaker] = useState(null);
  const [voices, setVoices] = useState([]);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const audioRef = useRef(null); // NEW

  useEffect(() => {
    const handleVoicesChanged = () => {
      const availableVoices = speechSynthesis.getVoices();
      setVoices(availableVoices);
    };

    speechSynthesis.addEventListener('voiceschanged', handleVoicesChanged);
    handleVoicesChanged();

    return () => {
      speechSynthesis.removeEventListener('voiceschanged', handleVoicesChanged);
    };
  }, []);

  const handleSubmit = () => {
    if (!text.trim()) return;

    const sentences = text.split(/(?<=[.!?])\s+/);
    let currentSpeaker = 0;

    const maleVoice = voices.find(v =>
      v.name.toLowerCase().includes('david') || v.name.toLowerCase().includes('male')
    );
    const femaleVoice = voices.find(v =>
      v.name.toLowerCase().includes('zira') || v.name.toLowerCase().includes('female')
    );

    const speak = (index) => {
      if (index >= sentences.length) {
        setSpeaker(null);
        setIsSpeaking(false);
        return;
      }

      const utterance = new SpeechSynthesisUtterance(sentences[index]);

      if (currentSpeaker === 0 && maleVoice) {
        utterance.voice = maleVoice;
      } else if (currentSpeaker === 1 && femaleVoice) {
        utterance.voice = femaleVoice;
      }

      setSpeaker(currentSpeaker);
      currentSpeaker = (currentSpeaker + 1) % 2;

      utterance.onstart = () => setIsSpeaking(true);
      utterance.onend = () => {
        setIsSpeaking(false);
        speak(index + 1);
      };

      speechSynthesis.speak(utterance);
    };

    speak(0);
  };

  const handleFileUpload = (e) => {
    const file = e.target.files[0];
    if (!file) return;
    const reader = new FileReader();
    reader.onload = (e) => {
      setText(e.target.result);
    };
    reader.readAsText(file);
  };

  return (
    <div className="min-h-screen bg-gray-900 text-white flex flex-col items-center justify-center p-6">
      <h1 className="text-3xl md:text-4xl font-bold mb-6 text-center">
        üéôÔ∏è Text to Podcast Generator
      </h1>

      <input
        type="file"
        accept=".txt"
        onChange={handleFileUpload}
        className="mb-4 text-white"
      />

      <InputSection text={text} setText={setText} onSubmit={handleSubmit} />
      <SpeakerDisplay speaker={speaker} />

      {/* Static audio for now (replace with your file) */}
      <audio
        ref={audioRef}
        controls
        src="/sample.mp3" // Replace with your file path
        className="mt-4"
      />

      <AudioVisualizer audioRef={audioRef} />
    </div>
  );
}

export default App;










import React, { useEffect, useRef } from 'react';

const AudioVisualizer = ({ audioRef }) => {
  const canvasRef = useRef(null);

  useEffect(() => {
    if (!audioRef.current) return;

    const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    const analyser = audioCtx.createAnalyser();
    analyser.fftSize = 256;

    const source = audioCtx.createMediaElementSource(audioRef.current);
    source.connect(analyser);
    analyser.connect(audioCtx.destination);

    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    const canvas = canvasRef.current;
    const canvasCtx = canvas.getContext('2d');

    const draw = () => {
      requestAnimationFrame(draw);

      analyser.getByteFrequencyData(dataArray);

      canvasCtx.fillStyle = '#111827'; // Tailwind slate-900
      canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

      const barWidth = (canvas.width / bufferLength) * 2.5;
      let x = 0;

      for (let i = 0; i < bufferLength; i++) {
        const barHeight = dataArray[i] / 2;

        canvasCtx.fillStyle = '#4ade80'; // Tailwind green-400
        canvasCtx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);

        x += barWidth + 1;
      }
    };

    draw();

    // Resume context on play (required in some browsers)
    const resume = () => audioCtx.resume();
    audioRef.current.addEventListener('play', resume);

    return () => {
      audioRef.current.removeEventListener('play', resume);
      audioCtx.close();
    };
  }, [audioRef]);

  return (
    <canvas
      ref={canvasRef}
      width={600}
      height={100}
      className="mt-4 border border-green-500 rounded"
    />
  );
};

export default AudioVisualizer;
