
import React, { useState, useEffect, useRef } from 'react';
import './index.css';
import InputSection from './components/InputSection';
import SpeakerDisplay from './components/SpeakerDisplay';
import AudioVisualizer from './components/AudioVisualizer';

function App() {
  const [text, setText] = useState('');
  const [speaker, setSpeaker] = useState(null);
  const [voices, setVoices] = useState([]);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const audioRef = useRef(null); // NEW

  useEffect(() => {
    const handleVoicesChanged = () => {
      const availableVoices = speechSynthesis.getVoices();
      setVoices(availableVoices);
    };

    speechSynthesis.addEventListener('voiceschanged', handleVoicesChanged);
    handleVoicesChanged();

    return () => {
      speechSynthesis.removeEventListener('voiceschanged', handleVoicesChanged);
    };
  }, []);

  const handleSubmit = () => {
    if (!text.trim()) return;

    const sentences = text.split(/(?<=[.!?])\s+/);
    let currentSpeaker = 0;

    const maleVoice = voices.find(v =>
      v.name.toLowerCase().includes('david') || v.name.toLowerCase().includes('male')
    );
    const femaleVoice = voices.find(v =>
      v.name.toLowerCase().includes('zira') || v.name.toLowerCase().includes('female')
    );

    const speak = (index) => {
      if (index >= sentences.length) {
        setSpeaker(null);
        setIsSpeaking(false);
        return;
      }

      const utterance = new SpeechSynthesisUtterance(sentences[index]);

      if (currentSpeaker === 0 && maleVoice) {
        utterance.voice = maleVoice;
      } else if (currentSpeaker === 1 && femaleVoice) {
        utterance.voice = femaleVoice;
      }

      setSpeaker(currentSpeaker);
      currentSpeaker = (currentSpeaker + 1) % 2;

      utterance.onstart = () => setIsSpeaking(true);
      utterance.onend = () => {
        setIsSpeaking(false);
        speak(index + 1);
      };

      speechSynthesis.speak(utterance);
    };

    speak(0);
  };

  const handleFileUpload = (e) => {
    const file = e.target.files[0];
    if (!file) return;
    const reader = new FileReader();
    reader.onload = (e) => {
      setText(e.target.result);
    };
    reader.readAsText(file);
  };

  return (
    <div className="min-h-screen bg-gray-900 text-white flex flex-col items-center justify-center p-6">
      <h1 className="text-3xl md:text-4xl font-bold mb-6 text-center">
        üéôÔ∏è Text to Podcast Generator
      </h1>

      <input
        type="file"
        accept=".txt"
        onChange={handleFileUpload}
        className="mb-4 text-white"
      />

      <InputSection text={text} setText={setText} onSubmit={handleSubmit} />
      <SpeakerDisplay speaker={speaker} />

      {/* Static audio for now (replace with your file) */}
      <audio
        ref={audioRef}
        controls
        src="/sample.mp3" // Replace with your file path
        className="mt-4"
      />

      <AudioVisualizer audioRef={audioRef} />
    </div>
  );
}

export default App;










import React, { useEffect, useRef } from 'react';

const AudioVisualizer = ({ audioRef }) => {
  const canvasRef = useRef(null);

  useEffect(() => {
    if (!audioRef.current) return;

    const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    const analyser = audioCtx.createAnalyser();
    analyser.fftSize = 256;

    const source = audioCtx.createMediaElementSource(audioRef.current);
    source.connect(analyser);
    analyser.connect(audioCtx.destination);

    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    const canvas = canvasRef.current;
    const canvasCtx = canvas.getContext('2d');

    const draw = () => {
      requestAnimationFrame(draw);

      analyser.getByteFrequencyData(dataArray);

      canvasCtx.fillStyle = '#111827'; // Tailwind slate-900
      canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

      const barWidth = (canvas.width / bufferLength) * 2.5;
      let x = 0;

      for (let i = 0; i < bufferLength; i++) {
        const barHeight = dataArray[i] / 2;

        canvasCtx.fillStyle = '#4ade80'; // Tailwind green-400
        canvasCtx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);

        x += barWidth + 1;
      }
    };

    draw();

    // Resume context on play (required in some browsers)
    const resume = () => audioCtx.resume();
    audioRef.current.addEventListener('play', resume);

    return () => {
      audioRef.current.removeEventListener('play', resume);
      audioCtx.close();
    };
  }, [audioRef]);

  return (
    <canvas
      ref={canvasRef}
      width={600}
      height={100}
      className="mt-4 border border-green-500 rounded"
    />
  );
};

export default AudioVisualizer;
